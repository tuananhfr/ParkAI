"""
Detection Service - Ch·∫°y AI detection trong thread ri√™ng
"""
import threading
import time
import numpy as np
from functools import lru_cache

import config


class Detection:
    """Detection object - Gi·ªëng demo code"""
    def __init__(self, coords, category, conf, metadata, imx500, picam2):
        self.category = category
        self.conf = conf
        # Use IMX500 convert_inference_coords nh∆∞ demo code
        self.box = imx500.convert_inference_coords(coords, metadata, picam2)


class DetectionService:
    """Service ch·∫°y AI detection"""
    
    def __init__(self, camera_manager, websocket_manager, ocr_service=None):
        self.camera_manager = camera_manager
        self.websocket_manager = websocket_manager
        self.ocr_service = ocr_service
        
        self.intrinsics = camera_manager.get_intrinsics()
        self.imx500 = camera_manager.get_imx500()
        self.picam2 = camera_manager.get_picam2()
        
        self.running = False
        self.detection_thread = None
        
        # Stats
        self.total_detections = 0
        self.total_frames = 0
        self.fps = 0
        self.last_fps_time = time.time()
        self.frames_in_second = 0

        # OCR throttling - ch·ªâ ch·∫°y m·ªói N frames
        self.ocr_frame_skip = config.OCR_FRAME_SKIP
        self.last_ocr_results = {}  # Cache OCR results by bbox

        # Statistics for debugging
        self.outputs_success = 0
        self.outputs_fail = 0

    def start(self):
        """B·∫Øt ƒë·∫ßu detection thread"""
        if self.running:
            return
        
        self.running = True
        self.detection_thread = threading.Thread(target=self._detection_loop, daemon=True)
        self.detection_thread.start()
    
    def stop(self):
        """D·ª´ng detection"""
        self.running = False

        if self.detection_thread:
            self.detection_thread.join(timeout=2)


    def _detection_loop(self):
        """Loop detection - T·∫¨N D·ª§NG IMX500, CH·ªà PARSE METADATA"""

        while self.running:
            try:
                frame_data = self.camera_manager.get_frame_for_detection()

                if frame_data is None:
                    continue

                # OPTIMIZATION: Kh√¥ng c·∫ßn frame - IMX500 ƒë√£ c√≥ bbox trong metadata
                metadata = frame_data['metadata']
                timestamp = frame_data['timestamp']
                frame_id = frame_data['frame_id']
                cached_outputs = frame_data.get('outputs')  # Get cached outputs (n·∫øu c√≥)

                # Parse detections t·ª´ IMX500 metadata (ƒë√£ c√≥ bbox s·∫µn)
                detections = self._parse_detections(metadata, cached_outputs)

                # Update stats
                self.total_frames += 1
                self.frames_in_second += 1
                current_time = time.time()

                if current_time - self.last_fps_time >= 1.0:
                    self.fps = self.frames_in_second
                    self.frames_in_second = 0
                    self.last_fps_time = current_time


                # Convert detections v√† run OCR n·∫øu enabled
                detection_results = []
                frame = frame_data.get('frame')

                for detection in detections:
                    # Detection object c√≥ .box (x, y, w, h) format
                    x, y, w, h = detection.box
                    category_idx = int(detection.category)
                    confidence = float(detection.conf)

                    labels = self._get_labels()
                    label = labels[category_idx] if category_idx < len(labels) else f"Class_{category_idx}"

                    detection_dict = {
                        'class': label,
                        'confidence': confidence,
                        'bbox': [int(x), int(y), int(w), int(h)],
                        'timestamp': timestamp,
                        'frame_id': frame_id
                    }

                    # Run OCR - CH·ªà M·ªñI N FRAMES ƒë·ªÉ gi·∫£m lag
                    if config.ENABLE_OCR and self.ocr_service and self.ocr_service.is_ready() and frame is not None:
                        # T·∫°o bbox key ƒë·ªÉ cache
                        bbox_key = (x, y, w, h)

                        # Ch·ªâ ch·∫°y OCR m·ªói N frames
                        should_run_ocr = (self.total_frames % self.ocr_frame_skip == 0)

                        if should_run_ocr:
                            try:
                                # Validate bbox trong frame boundaries
                                frame_h, frame_w = frame.shape[:2]
                                x_valid = max(0, min(x, frame_w - 1))
                                y_valid = max(0, min(y, frame_h - 1))
                                w_valid = min(w, frame_w - x_valid)
                                h_valid = min(h, frame_h - y_valid)

                                # Crop detection region
                                if w_valid > 10 and h_valid > 10:  # Ch·ªâ crop n·∫øu ƒë·ªß l·ªõn
                                    crop = frame[y_valid:y_valid+h_valid, x_valid:x_valid+w_valid]

                                    if crop.size > 0:
                                        text = self.ocr_service.recognize(crop)
                                        if text:
                                            detection_dict['text'] = text
                                            self.last_ocr_results[bbox_key] = text
                            except Exception as e:
                                print(f"‚ùå OCR error: {e}")
                        else:
                            # D√πng cached result n·∫øu c√≥
                            if bbox_key in self.last_ocr_results:
                                detection_dict['text'] = self.last_ocr_results[bbox_key]

                    detection_results.append(detection_dict)

                if len(detection_results) > 0:
                    self.total_detections += len(detection_results)

                # Broadcast LU√îN - k·ªÉ c·∫£ khi empty (ƒë·ªÉ frontend update smooth)
                self.websocket_manager.broadcast_detections(detection_results)
                if detection_results:
                    # Log detections with OCR text
                    for det in detection_results:
                        if 'text' in det:
                            print(f"üöó Bi·ªÉn s·ªë: {det['text']} (confidence: {det['confidence']:.2f})")

                # Cleanup OCR cache m·ªói 100 frames ƒë·ªÉ tr√°nh memory leak
                if self.total_frames % 100 == 0:
                    self.last_ocr_results.clear()

            except Exception as e:
                print(f"‚ùå Error: {e}")
                import traceback
                traceback.print_exc()
                time.sleep(0.1)

    def _parse_detections(self, metadata, cached_outputs=None):
        """Parse detections t·ª´ IMX500 - Gi·ªëng logic demo code"""
        try:
            # Use cached outputs t·ª´ camera_manager (n·∫øu c√≥) ƒë·ªÉ tr√°nh g·ªçi get_outputs 2 l·∫ßn
            if cached_outputs is not None:
                outputs = cached_outputs
            else:
                # Fallback: extract t·ª´ metadata (legacy path)
                outputs = self.imx500.get_outputs(metadata, add_batch=True)

            # Track statistics
            if outputs is None or len(outputs) < 3:
                self.outputs_fail += 1
                return []

            # Success
            self.outputs_success += 1

            # Check if model has postprocess built-in
            if self.intrinsics.postprocess == "nanodet":
                # Use nanodet postprocessing (nh∆∞ demo code)
                from picamera2.devices.imx500 import postprocess_nanodet_detection
                from picamera2.devices.imx500.postprocess import scale_boxes

                input_w, input_h = self.imx500.get_input_size()
                boxes, scores, classes = postprocess_nanodet_detection(
                    outputs=outputs[0],
                    conf=config.DETECTION_THRESHOLD,
                    iou_thres=config.IOU_THRESHOLD,
                    max_out_dets=config.MAX_DETECTIONS
                )[0]
                boxes = scale_boxes(boxes, 1, 1, input_h, input_w, False, False)
            else:
                # Model c√≥ built-in postprocessing - THEO ƒê√öNG DEMO CODE
                boxes = outputs[0][0]      # Shape: (300, 4)
                scores = outputs[1][0]     # Shape: (300,)
                classes = outputs[2][0]    # Shape: (300,)

                # Normalize ƒê√öNG nh∆∞ demo code
                if self.intrinsics.bbox_normalization:
                    input_w, input_h = self.imx500.get_input_size()
                    boxes = boxes / input_h  # CH·ªà chia cho HEIGHT

                # Swap bbox order ƒê√öNG nh∆∞ demo code
                if self.intrinsics.bbox_order == "xy":
                    boxes = boxes[:, [1, 0, 3, 2]]  # Swap y‚Üîx: (x,y,x,y) ‚Üí (y,x,y,x)

                # Reshape ƒê√öNG nh∆∞ demo code
                boxes = np.array_split(boxes, 4, axis=1)
                boxes = [arr.flatten() for arr in boxes]
                boxes = zip(*boxes)  # Generator, gi·ªëng demo code

            # Filter by threshold v√† create Detection objects
            detections = []
            for box, score, category in zip(boxes, scores, classes):
                if score > config.DETECTION_THRESHOLD:
                    # D√ôNG Detection class nh∆∞ demo code - convert_inference_coords() s·∫Ω handle ƒë√∫ng!
                    detection = Detection(box, category, score, metadata, self.imx500, self.picam2)

                    # Get bbox ƒë√£ ƒë∆∞·ª£c convert sang pixel coords
                    x, y, w, h = detection.box

                    # Calculate aspect ratio
                    aspect_ratio = w / h if h > 0 else 0

                    # Debug: Collect info
                    # Bi·ªÉn s·ªë Vi·ªát Nam: width/height th∆∞·ªùng 2.0 - 4.5
                    # Filter: ch·ªâ accept boxes N·∫∞M NGANG
                    if aspect_ratio > config.MIN_PLATE_ASPECT_RATIO:
                        detections.append(detection)

            return detections

        except Exception as e:
            # LU√îN log exception ƒë·∫ßu ti√™n, sau ƒë√≥ m·ªói 50 frames
            if not hasattr(self, '_parse_error_logged') or self.total_frames % 50 == 0:
                print(f"‚ùå Parse detection error: {e}")
                import traceback
                traceback.print_exc()
                self._parse_error_logged = True
            return []

    @lru_cache
    def _get_labels(self):
        """Get labels"""
        labels = self.intrinsics.labels
        if self.intrinsics.ignore_dash_labels:
            labels = [label for label in labels if label and label != "-"]
        return labels